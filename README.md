# Chain_of_Thoughts-COT

CoT prompting aims to encourage reasoning by getting the model to provide intermediate steps, 
leading to the definitive answer. This is done by prefixing the prompt with instructions to show 
its thinking.

There are three variants of CoT, zero-shot, few-shot and Automatic Chain-of-Thought (Auto-CoT).
![image](https://github.com/Jeevan672/Chain_of_Thoughts-COT-/assets/88030873/b5631f04-6f49-4d65-87a1-c88b5aa1bc57)

# zero-shot CoT

In # zero-shot CoT , we just add the instruction “Let’s think step by step!” to the prompt.

When asking an LLM to reason through a problem, it is often more effective to have it explain its 
reasoning before stating the final answer. This encourages the LLM to logically think through 
the problem first, rather than just guessing the answer and trying to justify it afterward. Asking
an LLM to explain its thought process aligns well with its core capabilities

Example- https://github.com/Jeevan672/Chain_of_Thoughts-COT-/blob/main/zero-shot-cot.ipynb

# Few-shot chain-of-thought

Few-shot chain-of-thought prompting is a few-shot prompt, where the reasoning is explained 
as part of the example solutions, with the idea to encourage an LLM to explain its reasoning 
before deciding.

Example Notes-


# Automatic Chain-of-Thought (Auto-CoT)

Loding....


